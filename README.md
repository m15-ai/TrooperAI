# ğŸ¥· Trooper AI

**Trooper AI** is a low-latency, voice-driven chatbot powered by local speech-to-text (Vosk), LLM-based text generation (via Ollama), neural text-to-speech (Piper), and audio effects (SoX). The assistant embodies an **Imperial Stormtrooper** â€” blunt, loyal, and unyielding.

Built for **Raspberry Pi 5**, this project turns your device into a fully autonomous voice unit â€” no cloud required, no keyboard necessary.

---

## ğŸ¯ Features

- ğŸ§  **Offline STT** via [Vosk](https://alphacephei.com/vosk/)
- ğŸ¤– **LLM Text Generation** via [Ollama](https://ollama.com/) (`gemma:2b`, `qwen`, etc.)
- ğŸ—£ï¸ **Neural TTS** via [Piper](https://github.com/rhasspy/piper)
- ğŸ›ï¸ **Voice FX Pipeline** with SoX:
  - Synthesized white noise
  - Bandpass filtering
  - Mixing for analog "comms" effect
- â±ï¸ **Full Timing Metrics** printed per turn
- ğŸ¤ **Live mic input / speaker output**
- ğŸ§¼ **Clean CLI logging** with no SoX warnings
- ğŸ‘®â€â™‚ï¸ Stormtrooper persona: cold, efficient, and direct

---

## ğŸ› ï¸ System Requirements

- Raspberry Pi 5 (8GB recommended)
- Python 3.11+
- Vosk model (e.g. `vosk-model-small-en-us-0.15`)
- Ollama installed with a compatible local model
- Piper voice installed (e.g. `en_US-amy-low`)
- SoX (`sudo apt install sox`)

---

## âš™ï¸ How It Works

1. `audio_loop.py` captures mic input and queues chunks.
2. `processing_loop()` runs:
   - âœ… Vosk STT (millisecond latency)
   - ğŸ¤– LLM inference via Ollama
   - ğŸ—£ï¸ Piper TTS, post-processed with SoX
   - ğŸ”Š Plays audio response
3. Full turn logs with timings (STT, inference, TTS, FX, playback)

---

## ğŸ§ª Sample Log

```txt
User: hello storm trooper
[Timing] Inference: 1160 ms
Stormtrooper: Silence is a weapon, and obedience is strength.
[Timing] Piper inference: 2011 ms
[Timing] Playback: 2895 ms
